{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LiverTox parser\n",
    "\n",
    "LiverTox has been moved from Toxnet to NLM bookshelf with a public domain licensing. It has not been retired and is still updated. NLM bookshelf has an ftp server for retrieving open-licensed materials.  In the process of migrating LiverTox over, it has also been more strictly formatted, making it slightly more easy to parse for information.\n",
    "\n",
    "To obtain the latest dataset, pull the ftp index from here:\n",
    "ftp://ftp.ncbi.nlm.nih.gov/pub/litarch/file_list.txt\n",
    "\n",
    "Next, search for LiverTox and get the url. Every entry in livertox is stored as a pdf and xml file in the compressed file. The filename is the livertox urlstub. The urlbase for LiverTox is https://www.ncbi.nlm.nih.gov/books/n/livertox/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidataintegrator import wdi_core, wdi_login, wdi_helpers\n",
    "from wikidataintegrator.ref_handlers import update_retrieved_if_new_multiple_refs\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import requests\n",
    "import ftplib\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import ipywidgets \n",
    "import widgetsnbextension\n",
    "import xml.etree.ElementTree as et \n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that the property start date is used for list date.\n",
    "## When placed in the references, Deltabot moved it out as a qualifier\n",
    "\n",
    "from datetime import datetime\n",
    "import copy\n",
    "def create_reference(prop65_url):\n",
    "    refStatedIn = wdi_core.WDItemID(value=\"Q28455381\", prop_nr=\"P248\", is_reference=True)\n",
    "    timeStringNow = datetime.now().strftime(\"+%Y-%m-%dT00:00:00Z\")\n",
    "    refRetrieved = wdi_core.WDTime(timeStringNow, prop_nr=\"P813\", is_reference=True)\n",
    "    refURL = wdi_core.WDUrl(value=prop65_url, prop_nr=\"P854\", is_reference=True)\n",
    "    return [refStatedIn, refRetrieved, refURL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logging in...\")\n",
    "import wdi_user_config ## Credentials stored in a wdi_user_config file\n",
    "login_dict = wdi_user_config.get_credentials()\n",
    "login = wdi_login.WDLogin(login_dict['WDUSER'], login_dict['WDPASS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_dict = {\n",
    "    'ftp_index':'ftp://ftp.ncbi.nlm.nih.gov/pub/litarch/file_list.txt',\n",
    "    'ftp_base':'ftp://ftp.ncbi.nlm.nih.gov/pub/litarch/',\n",
    "    'bookshelf_base':'https://www.ncbi.nlm.nih.gov/books/n/livertox/',\n",
    "    'local_data':'data/'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch the index file to determine the url of the current livertox dataset\n",
    "#bookshelf_index = ftplib.FTP(urls_dict['ftp_base'])\n",
    "#bookshelf_index.login()\n",
    "\n",
    "#print(bookshelf_index.text)\n",
    "\n",
    "## This is an example of how to use the ftplib to pull things from an ftp server\n",
    "\"\"\"\n",
    "import os\n",
    "from ftplib import FTP\n",
    " \n",
    "ftp = FTP(\"www.myWebsite.com\", \"USERNAME\", \"PASSWORD\")\n",
    "ftp.login()\n",
    "ftp.retrlines(\"LIST\")\n",
    " \n",
    "ftp.cwd(\"folderOne\")\n",
    "ftp.cwd(\"subFolder\") # or ftp.cwd(\"folderOne/subFolder\")\n",
    " \n",
    "listing = []\n",
    "ftp.retrlines(\"LIST\", listing.append)\n",
    "words = listing[0].split(None, 8)\n",
    "filename = words[-1].lstrip()\n",
    " \n",
    "# download the file\n",
    "local_filename = os.path.join(r\"c:\\myfolder\", filename)\n",
    "lf = open(local_filename, \"wb\")\n",
    "ftp.retrbinary(\"RETR \" + filename, lf.write, 8*1024)\n",
    "lf.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3372\n"
     ]
    }
   ],
   "source": [
    "## Once the file has been downloaded, process it for data of interest\n",
    "import tarfile\n",
    "import tempfile\n",
    "import stat\n",
    "\n",
    "tar_file = urls_dict['local_data']+'livertox_NBK547852.tar.gz'\n",
    "tar = tarfile.open(tar_file, \"r:gz\")\n",
    "members = tar.getmembers()\n",
    "print(len(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quinine\n",
      "Leflunomide\n",
      "Propranolol\n"
     ]
    }
   ],
   "source": [
    "phenotypes = []\n",
    "drug_types = []\n",
    "misc_pages = []\n",
    "drug_page = []\n",
    "for member in members[11:15]:\n",
    "    if '.nxml' in str(member):\n",
    "        extracted = tar.extractfile(member)\n",
    "        tree = et.parse(extracted)\n",
    "        root = tree.getroot()\n",
    "        try:\n",
    "            metainfo = root.find('book-part').find('book-part-meta')\n",
    "            url_stub = metainfo.find('book-part-id').text\n",
    "            drug_name = metainfo.find('title-group').find('title').text\n",
    "            date_info = metainfo.find('pub-history').find('date')\n",
    "            date_day = date_info.find('day').text\n",
    "            date_month = date_info.find('month').text\n",
    "            date_year = date_info.find('year').text\n",
    "            tmp_date = str(date_year)+\"-\"+str(date_month)+\"-\"+str(date_day)\n",
    "            if date_info.attrib['date-type'] == 'updated':\n",
    "                update_date = tmp_date\n",
    "                original_date = None\n",
    "            else:\n",
    "                original_date = tmp_date\n",
    "                update_date = None\n",
    "                \n",
    "            basic_meta = {'Title':drug_name,'url_stub':url_stub,\n",
    "                          'last_update':update_date,'original_date':original_date}\n",
    "            ## Determine if the page is about a drug, drug class, or phenotype\n",
    "            if 'Phenotypes' in url_stub:\n",
    "                phenotypes.append(basic_meta)\n",
    "            else:\n",
    "                book_content = root.find('book-part').find('body').find('sec')\n",
    "                ## We're only interested in the Overview section of the drug and drug class pages\n",
    "                if \".OVERVIEW\" in book_content.attrib['id']:\n",
    "                    print(url_stub)\n",
    "                    basic_tags = [elem.tag for elem in book_content.iter()]\n",
    "                    if 'list' in basic_tags:\n",
    "                        drug_types.append(basic_meta)\n",
    "                        print('listed')\n",
    "                    else:\n",
    "                        id_to_find = url_stub+\".Hepatotoxicity\"\n",
    "                        print(hepatox_sxn)    \n",
    "                        \n",
    "                        \"\"\"\n",
    "                        Need to find a way to pull section of interest for parsing\n",
    "                        section = book_content.find('sec')\n",
    "                        if section.attrib['id']==url_stub+\".Hepatotoxicity\":\n",
    "                            overview_text = section.text\n",
    "                            score_start = overview_text.find('Likelihood score: ')\n",
    "                            score_end = overview_text[score_start:len(overview_text)].find('</p>')\n",
    "                            likelihood_score = overview_text[score_start:score_start+score_end]\n",
    "                            print(likelihood_score)\n",
    "                        ## if the page has a Hepatoxicity section, it's likely a drug \n",
    "\n",
    "                            ## the page is a drug page, so we can parse for toxicity scores\"\"\"\n",
    "                                  \n",
    "        except:\n",
    "            misc_pages.append(str(root))\n",
    "            #print(member)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(drug_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
